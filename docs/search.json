[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Miya(Mia) Huang",
    "section": "",
    "text": "Welcome!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this field experiment, each donor in the sample was randomly assigned to receive one of several versions of a fundraising letter. The control group received the nonprofit’s standard appeal—a typical letter asking for support, with no mention of any special incentives.\nThe treatment group, on the other hand, received letters that included a matching grant offer. These letters stated that a concerned member of the organization would match the recipient’s donation at a fixed rate. Every dollar donated would be matched immediately, increasing the total contribution the organization would receive.\nThe treatment letters varied across three key dimensions:\n\nMatching ratio\nDonors were randomly assigned to receive a match offer of 1:1, 2:1, or 3:1, meaning the organization would receive $2, $3, or $4 for every $1 donated.\nMaximum match amount\nThe total available match funding was stated as either $25,000, $50,000, $100,000, or left unstated.\nSuggested donation amount\nEach letter included a reply card with three suggested gift levels based on the donor’s previous highest contribution: the same amount, 1.25×, or 1.5×. One of these was used as an example in the match statement.\n\nAside from these randomized variations, all letters were identical in format, tone, and content. This design allowed the researchers to isolate the effect of the matching grant mechanism and its specific features on donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this field experiment, each donor in the sample was randomly assigned to receive one of several versions of a fundraising letter. The control group received the nonprofit’s standard appeal—a typical letter asking for support, with no mention of any special incentives.\nThe treatment group, on the other hand, received letters that included a matching grant offer. These letters stated that a concerned member of the organization would match the recipient’s donation at a fixed rate. Every dollar donated would be matched immediately, increasing the total contribution the organization would receive.\nThe treatment letters varied across three key dimensions:\n\nMatching ratio\nDonors were randomly assigned to receive a match offer of 1:1, 2:1, or 3:1, meaning the organization would receive $2, $3, or $4 for every $1 donated.\nMaximum match amount\nThe total available match funding was stated as either $25,000, $50,000, $100,000, or left unstated.\nSuggested donation amount\nEach letter included a reply card with three suggested gift levels based on the donor’s previous highest contribution: the same amount, 1.25×, or 1.5×. One of these was used as an example in the match statement.\n\nAside from these randomized variations, all letters were identical in format, tone, and content. This design allowed the researchers to isolate the effect of the matching grant mechanism and its specific features on donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset consists of 50,083 observations and 51 variables, representing prior donors who were part of a large-scale direct mail fundraising experiment. Each row corresponds to an individual who received a solicitation letter, and the variables capture both treatment assignments and individual characteristics.\nThe bar plots show the distribution of key categorical variables in the dataset. The sample is unbalanced across treatment groups by design, with approximately two-thirds assigned to treatment. Only 2.1% of individuals donated, indicating a low response rate. Most of the sample resides in blue states (59.5%), and the majority of donors are male (70.6%) and not donating as a couple (88.7%).\nThe histograms of numeric variables show that both donation-related and historical giving behaviors are highly skewed to the right. Most donation amounts are under $100, and both highest past donation and frequency of past donations exhibit long right tails, suggesting that a small subset of donors account for a disproportionately large share of past giving. The recency variable (mrm2) also shows many donors who haven’t contributed recently, with the most frequent values clustered between 0 and 12 months.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# categorical\ncategorical_vars = ['treatment', 'gave', 'red0', 'female', 'couple']\nlabel_map = {\n    'treatment': {0: 'Control', 1: 'Treatment'},\n    'gave': {0: 'Did Not Give', 1: 'Gave'},\n    'red0': {0: 'Blue State', 1: 'Red State'},\n    'female': {0: 'Male', 1: 'Female'},\n    'couple': {0: 'Single', 1: 'Couple'}\n}\n\nfig, axes = plt.subplots(2, 3, figsize=(16, 8))\naxes = axes.flatten()\n\nfor i, var in enumerate(categorical_vars):\n    ax = axes[i]\n    counts = df[var].value_counts().sort_index()\n    labels = list(label_map[var].values())\n    bars = ax.bar(labels, counts.values, color=sns.color_palette(\"pastel\"))\n\n    for bar, count in zip(bars, counts.values):\n        pct = count / df.shape[0]\n        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{pct:.1%}',\n                ha='center', va='bottom', fontsize=9)\n\n    ax.set_title(f\"{var.capitalize()} Distribution\")\n    ax.set_ylabel(\"Count\")\n\nif len(categorical_vars) &lt; len(axes):\n    fig.delaxes(axes[-1])\n\nplt.tight_layout()\nplt.show()\n\n# numeric\nnumeric_vars = ['amount', 'hpa', 'mrm2', 'freq']\ntitles = {\n    'amount': 'Donation Amount',\n    'hpa': 'Highest Past Donation',\n    'mrm2': 'Months Since Last Donation',\n    'freq': 'Donation Frequency'\n}\n\nxlims = {\n    'amount': (0, 200),\n    'hpa': (0, 250),\n    'mrm2': (0, 60),\n    'freq': (0, 50)\n}\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 6))\naxes = axes.flatten()\n\nfor i, var in enumerate(numeric_vars):\n    ax = axes[i]\n    data = df[df['gave'] == 1][var] if var == 'amount' else df[var]\n    \n    sns.histplot(data, bins=30, kde=True, ax=ax, color='skyblue')\n    ax.set_title(titles[var])\n    ax.set_xlabel(var)\n    ax.set_ylabel(\"Frequency\")\n    ax.set_xlim(xlims[var])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")  \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy.stats import t as t_dist\n\n# Variables\ntest_vars = ['mrm2', 'hpa', 'freq']\nvar_labels = {\n    'mrm2': 'Months Since Last Donation',\n    'hpa': 'Highest Past Donation',\n    'freq': 'Donation Frequency'\n}\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\naxes = axes.flatten()\n\nfor i, var in enumerate(test_vars):\n    means = [\n        df[df['treatment'] == 0][var].mean(),\n        df[df['treatment'] == 1][var].mean()\n    ]\n    labels = ['Control', 'Treatment']\n    colors = ['#6baed6', '#fd8d3c']\n\n    bars = axes[i].bar(labels, means, color=colors)\n    axes[i].set_title(var_labels[var])\n    axes[i].set_ylabel(\"Mean\")\n\n    # Add value labels\n    for bar, mean in zip(bars, means):\n        axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n                     f\"{mean:.2f}\", ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\n# t-test and regression comparison\nresults = []\n\nfor var in test_vars:\n    x1 = df[df[\"treatment\"] == 1][var].dropna()\n    x0 = df[df[\"treatment\"] == 0][var].dropna()\n\n    mean1 = x1.mean()\n    mean0 = x0.mean()\n    diff = mean1 - mean0\n    var1 = x1.var(ddof=1)\n    var0 = x0.var(ddof=1)\n    n1 = len(x1)\n    n0 = len(x0)\n\n    se = np.sqrt(var1 / n1 + var0 / n0)\n    t_stat = diff / se\n\n    df_denom = (var1/n1 + var0/n0)**2 / ((var1**2 / (n1**2 * (n1 - 1))) + (var0**2 / (n0**2 * (n0 - 1))))\n    ttest_p = 2 * (1 - t_dist.cdf(abs(t_stat), df=df_denom))\n\n    X = sm.add_constant(df[['treatment']])\n    model = sm.OLS(df[var], X, missing='drop').fit()\n    reg_t = model.tvalues['treatment']\n    reg_p = model.pvalues['treatment']\n\n    results.append({\n        'Variable': var,\n        'Mean_Treatment': round(mean1, 3),\n        'Mean_Control': round(mean0, 3),\n        'Difference': round(diff, 3),\n        'T-test t': round(t_stat, 3),\n        'T-test p': round(ttest_p, 4),\n        'Reg t': round(reg_t, 3),\n        'Reg p-value': round(reg_p, 4)\n    })\n\npd.DataFrame(results)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean_Treatment\nMean_Control\nDifference\nT-test t\nT-test p\nReg t\nReg p-value\n\n\n\n\n0\nmrm2\n13.012\n12.998000\n0.014\n0.120\n0.9049\n0.119\n0.9049\n\n\n1\nhpa\n59.597\n58.959999\n0.637\n0.970\n0.3318\n0.944\n0.3451\n\n\n2\nfreq\n8.035\n8.047000\n-0.012\n-0.111\n0.9117\n-0.111\n0.9117\n\n\n\n\n\n\n\nThe bar plots visually confirm that the treatment and control groups are nearly identical in their pre-treatment characteristics. There is no meaningful difference in the average months since last donation, highest past donation, or donation frequency.\nStatistical tests further support this conclusion. Both t-tests (using the class formula) and simple regressions yield non-significant results at the 95% confidence level, with very small t-statistics and large p-values across all variables.\nThese findings align with Table 1 in Karlan and List (2007), providing strong evidence that the random assignment was successfully implemented and that treatment and control groups are balanced in observable covariates. This supports the internal validity of any subsequent causal analysis."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\n\ndonation_rates = df.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\ncolors = ['#6baed6', '#fd8d3c']\n\n# Plot\nfig, ax = plt.subplots(figsize=(6, 4))\nbars = ax.bar(labels, donation_rates.values, color=colors)\n\nfor bar, rate in zip(bars, donation_rates.values):\n    ax.text(bar.get_x() + bar.get_width() / 2,\n            bar.get_height() + 0.002,\n            f\"{rate:.2%}\", ha='center', va='bottom', fontsize=10)\n\nax.set_ylabel(\"Proportion Donated\")\nax.set_title(\"Donation Rate by Treatment Group\")\nplt.ylim(0, max(donation_rates.values) + 0.01)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe treatment group has a higher donation rate (2.20%) than the control group (1.79%), suggesting a positive effect of the matching offer on donor response.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy.stats import t as t_dist\n\ny_treat = df[df[\"treatment\"] == 1][\"gave\"]\ny_ctrl = df[df[\"treatment\"] == 0][\"gave\"]\n\nmean_treat = y_treat.mean()\nmean_ctrl = y_ctrl.mean()\ndiff = mean_treat - mean_ctrl\nn_treat = len(y_treat)\nn_ctrl = len(y_ctrl)\nvar_treat = y_treat.var(ddof=1)\nvar_ctrl = y_ctrl.var(ddof=1)\n\nse = np.sqrt(var_treat / n_treat + var_ctrl / n_ctrl)\nt_stat = diff / se\ndf_denom = (var_treat/n_treat + var_ctrl/n_ctrl)**2 / (\n    (var_treat**2 / (n_treat**2 * (n_treat - 1))) +\n    (var_ctrl**2 / (n_ctrl**2 * (n_ctrl - 1)))\n)\np_val = 2 * (1 - t_dist.cdf(abs(t_stat), df=df_denom))\n\nX = sm.add_constant(df[\"treatment\"])\nmodel = sm.OLS(df[\"gave\"], X, missing ='drop').fit()\n\n# results\nprint(\"T-test result:\")\nprint(f\"  • Mean difference in donation rate (Treatment - Control): { round(diff, 4)}\")\nprint(f\"  • t-statistic: {round(t_stat, 3)}\")\nprint(f\"  • p-value: {round(p_val, 4)}\")\n\nprint(\"\\nLinear regression result:\")\nprint(f\"  • Coefficient on treatment: {round(model.params['treatment'], 4)}\")\nprint(f\"  • t-statistic: {round(model.tvalues['treatment'], 3)}\")\nprint(f\"  • p-value: {round(model.pvalues['treatment'], 4)}\")\n\n\nT-test result:\n  • Mean difference in donation rate (Treatment - Control): 0.0042\n  • t-statistic: 3.209\n  • p-value: 0.0013\n\nLinear regression result:\n  • Coefficient on treatment: 0.0042\n  • t-statistic: 3.101\n  • p-value: 0.0019\n\n\nBoth the t-test and the linear regression show that the treatment group had a higher donation rate than the control group, and this difference is statistically significant at the 1% level. Specifically, receiving a matching grant offer increases the probability of donating by about 0.42 percentage points—rising from roughly 1.79% in the control group to 2.21% in the treatment group. While this absolute change may appear small, it represents a relative increase of over 20%, which is substantial given the typically low baseline response rate in charitable giving.\nTo further support this finding, I estimate a probit model where the outcome is whether a donation was made and the explanatory variable is treatment assignment. The coefficient on treatment is 0.087, which is also statistically significant at the 1% level. Although the coefficient cannot be interpreted directly as a probability, it indicates an increase in the latent propensity to donate among individuals who received the matching message.\nTaken together, the results provide consistent evidence that even modest psychological framing—such as mentioning that a donation will be matched—can meaningfully increase donor response.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\n\nfrom statsmodels.discrete.discrete_model import Probit\nimport statsmodels.api as sm\n\nX = sm.add_constant(df['treatment'])\nprobit_model = Probit(df['gave'], X).fit()\n\nprint(probit_model.summary())\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Sun, 20 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        14:40:23   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nI conduct three pairwise t-tests comparing donation rates between match ratios (2:1 vs. 1:1, 3:1 vs. 1:1, and 3:1 vs. 2:1). The differences in mean donation rates across these groups are all very small and none are statistically significant at the 5% level. All p-values are well above 0.30. This suggests that the presence of a match itself may be sufficient to motivate behavior, while increasing the match ratio beyond 1:1 offers little incremental benefit.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import t as t_dist\n\ntreatment_df = df[df[\"treatment\"] == 1]\n\nratios = {\n    1: treatment_df[treatment_df[\"ratio\"] == 1][\"gave\"],\n    2: treatment_df[treatment_df[\"ratio\"] == 2][\"gave\"],\n    3: treatment_df[treatment_df[\"ratio\"] == 3][\"gave\"]\n}\n\n# t-test\ndef manual_ttest(group1, group2):\n    mean_diff = group1.mean() - group2.mean()\n    se = np.sqrt(group1.var(ddof=1)/len(group1) + group2.var(ddof=1)/len(group2))\n    t_stat = mean_diff / se\n    df_denom = (group1.var(ddof=1)/len(group1) + group2.var(ddof=1)/len(group2))**2 / (\n        (group1.var(ddof=1)**2 / ((len(group1)**2)*(len(group1)-1))) + \n        (group2.var(ddof=1)**2 / ((len(group2)**2)*(len(group2)-1)))\n    )\n    p_val = 2 * (1 - t_dist.cdf(abs(t_stat), df=df_denom))\n    return round(mean_diff, 4), round(t_stat, 3), round(p_val, 4)\n\nresults = []\nfor high, low in [(2, 1), (3, 1), (3, 2)]:\n    diff, t_stat, p_val = manual_ttest(ratios[high], ratios[low])\n    results.append({\n        \"Comparison\": f\"{high}:1 vs {low}:1\",\n        \"Mean Diff\": diff,\n        \"T-stat\": t_stat,\n        \"P-value\": p_val\n    })\n\npd.DataFrame(results)\n\n\n\n\n\n\n\n\n\nComparison\nMean Diff\nT-stat\nP-value\n\n\n\n\n0\n2:1 vs 1:1\n0.0019\n0.965\n0.3345\n\n\n1\n3:1 vs 1:1\n0.0020\n1.015\n0.3101\n\n\n2\n3:1 vs 2:1\n0.0001\n0.050\n0.9600\n\n\n\n\n\n\n\nTo determine whether higher match ratios influence the likelihood of donating, I regress the binary outcome gave on the categorical variable ratio, using only the treatment group. The 1:1 match ratio serves as the reference category, and the model estimates how donation rates differ under 2:1 and 3:1 matching offers.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\n\ntreat_df = df[df[\"ratio\"].isin([1, 2, 3])].copy()\n\ntreat_df[\"ratio\"] = treat_df[\"ratio\"].astype(\"category\")\n\nimport statsmodels.formula.api as smf\nmodel = smf.ols(\"gave ~ C(ratio, Treatment(reference=1))\", data=treat_df).fit()\n\nparams = model.params\npvals = model.pvalues\n\nprint(\"Linear regression comparing match ratios (baseline: 1:1):\")\nprint(f\"  • Intercept (1:1 match): {params['Intercept']:.4f}\")\nprint(f\"  • 2:1 vs 1:1 match: Coef = {params['C(ratio, Treatment(reference=1))[T.2]']:.4f}, p = {pvals['C(ratio, Treatment(reference=1))[T.2]']:.4f}\")\nprint(f\"  • 3:1 vs 1:1 match: Coef = {params['C(ratio, Treatment(reference=1))[T.3]']:.4f}, p = {pvals['C(ratio, Treatment(reference=1))[T.3]']:.4f}\")\n\n\nLinear regression comparing match ratios (baseline: 1:1):\n  • Intercept (1:1 match): 0.0207\n  • 2:1 vs 1:1 match: Coef = 0.0019, p = 0.3383\n  • 3:1 vs 1:1 match: Coef = 0.0020, p = 0.3133\n\n\nThe estimated coefficients for ratio2 and ratio3 are positive, suggesting slightly higher donation rates compared to the 1:1 baseline. However, both coefficients are not statistically significant (p-values &gt; 0.3), indicating that the observed differences could be due to random variation rather than a true treatment effect.\nTo assess whether increasing the match ratio leads to higher response, I compared donation rates directly from the data and from the regression coefficients.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\n\nrate_1 = df[(df[\"treatment\"] == 1) & (df[\"ratio\"] == 1)][\"gave\"].mean()\nrate_2 = df[(df[\"treatment\"] == 1) & (df[\"ratio\"] == 2)][\"gave\"].mean()\nrate_3 = df[(df[\"treatment\"] == 1) & (df[\"ratio\"] == 3)][\"gave\"].mean()\n\ndiff_2_vs_1_data = rate_2 - rate_1\ndiff_3_vs_2_data = rate_3 - rate_2\n\ncoef_2 = model.params['C(ratio, Treatment(reference=1))[T.2]']\ncoef_3 = model.params['C(ratio, Treatment(reference=1))[T.3]']\ndiff_3_vs_2_coef = coef_3 - coef_2\n\nprint(\"Donation rate differences (direct from data):\")\nprint(f\"  • 2:1 vs 1:1: {round(diff_2_vs_1_data, 4)}\")\nprint(f\"  • 3:1 vs 2:1: {round(diff_3_vs_2_data, 4)}\")\n\nprint(\"\\nEstimated difference from regression coefficients:\")\nprint(f\"  • 2:1 vs 1:1: {round(coef_2, 4)}\")\nprint(f\"  • 3:1 vs 2:1: {round(diff_3_vs_2_coef, 4)}\")\n\n\nDonation rate differences (direct from data):\n  • 2:1 vs 1:1: 0.0019\n  • 3:1 vs 2:1: 0.0001\n\nEstimated difference from regression coefficients:\n  • 2:1 vs 1:1: 0.0019\n  • 3:1 vs 2:1: 0.0001\n\n\nMoving from a 1:1 to a 2:1 match produced a small increase of 0.19%, while the difference between 3:1 and 2:1 was nearly zero (0.01%). These results were mirrored exactly in the regression estimates.\nIn practical terms, offering a match matters, but increasing the match size does not appear to further improve donation response. For fundraisers, this suggests that a basic 1:1 match may be just as effective as higher ratios, but at a lower cost.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nI regress donation amount on the match ratio using the treatment group, with 1:1 as the reference group. The baseline average donation under 1:1 is $0.94. Compared to this:\n\nThe 2:1 group gives $0.09 more (p = 0.46)\nThe 3:1 group gives almost the same (p = 0.99)\n\nThis suggests that higher match ratios do not meaningfully affect how much people donate, even if they influence whether they donate at all.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\n\nimport statsmodels.formula.api as smf\n\namount_df = df[(df[\"treatment\"] == 1) & (df[\"ratio\"].isin([1, 2, 3]))].copy()\n\n\namount_df[\"ratio\"] = amount_df[\"ratio\"].astype(\"category\")\namount_df[\"ratio\"] = amount_df[\"ratio\"].cat.remove_unused_categories()\n\nmodel_amount = smf.ols(\"amount ~ C(ratio, Treatment(reference=1))\", data=amount_df).fit()\n\nmodel_amount.summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.3651\n\n\nDate:\nSun, 20 Apr 2025\nProb (F-statistic):\n0.694\n\n\nTime:\n14:40:24\nLog-Likelihood:\n-1.2063e+05\n\n\nNo. Observations:\n33396\nAIC:\n2.413e+05\n\n\nDf Residuals:\n33393\nBIC:\n2.413e+05\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.9367\n0.085\n11.026\n0.000\n0.770\n1.103\n\n\nC(ratio, Treatment(reference=1))[T.2]\n0.0895\n0.120\n0.745\n0.456\n-0.146\n0.325\n\n\nC(ratio, Treatment(reference=1))[T.3]\n0.0011\n0.120\n0.009\n0.993\n-0.234\n0.237\n\n\n\n\n\n\n\n\nOmnibus:\n64921.717\nDurbin-Watson:\n2.010\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n172634606.522\n\n\nSkew:\n15.430\nProb(JB):\n0.00\n\n\nKurtosis:\n353.872\nCond. No.\n3.73\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n I regress donation amount on the match ratio using only individuals who made a donation. The average donation in the 1:1 group is $45.14. Compared to this:\n\nThe 2:1 group gives $0.19 more (p = 0.96)\nThe 3:1 group gives $3.89 less (p = 0.31)\n\nThese differences are small and statistically insignificant. This suggests that once someone decides to donate, the size of the match does not influence how much they give.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\n\nimport statsmodels.formula.api as smf\n\namount_df = df[(df[\"treatment\"] == 1) & (df[\"amount\"] &gt; 0) & (df[\"ratio\"].isin([1, 2, 3]))].copy()\n\namount_df[\"ratio\"] = amount_df[\"ratio\"].astype(\"category\")\namount_df[\"ratio\"] = amount_df[\"ratio\"].cat.remove_unused_categories()\n\nmodel_amount = smf.ols(\"amount ~ C(ratio, Treatment(reference=1))\", data=amount_df).fit()\n\nmodel_amount.summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.002\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.001\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.7504\n\n\nDate:\nSun, 20 Apr 2025\nProb (F-statistic):\n0.473\n\n\nTime:\n14:40:24\nLog-Likelihood:\n-3794.3\n\n\nNo. Observations:\n736\nAIC:\n7595.\n\n\nDf Residuals:\n733\nBIC:\n7608.\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n45.1429\n2.765\n16.324\n0.000\n39.714\n50.572\n\n\nC(ratio, Treatment(reference=1))[T.2]\n0.1944\n3.829\n0.051\n0.960\n-7.322\n7.711\n\n\nC(ratio, Treatment(reference=1))[T.3]\n-3.8911\n3.825\n-1.017\n0.309\n-11.400\n3.618\n\n\n\n\n\n\n\n\nOmnibus:\n458.865\nDurbin-Watson:\n1.918\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n5192.758\n\n\nSkew:\n2.659\nProb(JB):\n0.00\n\n\nKurtosis:\n14.876\nCond. No.\n3.83\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n The histograms display the distribution of donation amounts among individuals who donated, separated by treatment and control groups. Both distributions are heavily right-skewed, with most donations concentrated under $100.\nThe treatment group’s average donation is $43.87, while the control group’s average is slightly higher at $45.54. Despite the visual and numerical difference, the gap is small and not statistically significant, reinforcing earlier regression results that match offers influence whether people give, but not how much they give once they’ve decided to donate.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndonors = df[df[\"amount\"] &gt; 0]\n\ndonors_treat = donors[donors[\"treatment\"] == 1]\ndonors_ctrl = donors[donors[\"treatment\"] == 0]\n\nmean_treat = donors_treat[\"amount\"].mean()\nmean_ctrl = donors_ctrl[\"amount\"].mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# treatment group\nsns.histplot(donors_treat[\"amount\"], bins=30, ax=axes[0], color='skyblue')\naxes[0].axvline(mean_treat, color='red', linestyle='--')  # Add vertical line for mean\naxes[0].set_title(\"Treatment\")\naxes[0].set_xlabel(\"Donation Amount\")\naxes[0].set_ylabel(\"Number of Donors\")\naxes[0].text(mean_treat + 2, axes[0].get_ylim()[1]*0.9, f\"Mean = ${mean_treat:.2f}\", color='red')\n\n# control group\nsns.histplot(donors_ctrl[\"amount\"], bins=30, ax=axes[1], color='lightgreen')\naxes[1].axvline(mean_ctrl, color='red', linestyle='--')\naxes[1].set_title(\"Control\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].text(mean_ctrl + 2, axes[1].get_ylim()[1]*0.9, f\"Mean = ${mean_ctrl:.2f}\", color='red')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nThe plot shows the cumulative average difference in donation amounts between the treatment and control groups, based on 10,000 simulated donor pairs. Initially, the cumulative average fluctuates substantially, reflecting noise in small samples. As the number of simulated pairs increases, the cumulative average steadily converges toward the true mean difference (indicated by the red dashed line).\nThis pattern illustrates the Law of Large Numbers: with enough data, the average of simulated differences approximates the population-level treatment effect. In this case, the cumulative average stabilizes around the true mean difference, providing visual confirmation that our estimate becomes more reliable as sample size increases.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\nnp.random.seed(123)\n\ncontrol_data = df[(df[\"treatment\"] == 0) & (df[\"amount\"] &gt; 0)][\"amount\"]\ntreat_data = df[(df[\"treatment\"] == 1) & (df[\"amount\"] &gt; 0)][\"amount\"]\n\n# simulation\ncontrol_draws = np.random.choice(control_data, size=100000, replace=True)\ntreat_draws = np.random.choice(treat_data, size=10000, replace=True)\n\ndiffs = treat_draws - control_draws[:10000]\ncum_avg_diff = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\ntrue_diff = treat_data.mean() - control_data.mean()\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cum_avg_diff, label=\"Cumulative Avg. Difference\", color='steelblue', linewidth=2)\nplt.axhline(y=true_diff, color='crimson', linestyle='--', linewidth=2, label=\"True Mean Difference\")\n\nplt.xlabel(\"Number of Simulated Pairs\", fontsize=12)\nplt.ylabel(\"Cumulative Average (Treatment - Control)\", fontsize=12)\nplt.title(\"Cumulative Average of Donation Differences\\nSimulated from Treatment and Control Groups\", fontsize=14, fontweight='bold')\nplt.legend()\nplt.grid(alpha=0.3)\nplt.xlim(0, 10000)\nplt.ylim(-20, 20)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nThese histograms show the distribution of simulated mean donation differences (treatment minus control) across 1000 replications, at four different sample sizes.\nAs the sample size increases, the distributions become narrower and more centered. This reflects a reduction in uncertainty—with small samples, estimates of the mean difference vary widely due to random noise. As the number of observations grows, the law of large numbers ensures that sample estimates converge toward the true underlying difference, and the variability across simulations shrinks.\nAt all sample sizes, the distributions tend to center slightly below zero, which is consistent with the observed data where treatment donors gave slightly less than control donors, on average. While the difference is small and not statistically significant, the simulation reinforces that larger sample sizes produce more stable and precise estimates, even when the underlying effect is near zero.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_stata(\"data/karlan_list_2007.dta\")\nnp.random.seed(123)\n\ncontrol_data = df[(df[\"treatment\"] == 0) & (df[\"amount\"] &gt; 0)][\"amount\"].values\ntreat_data = df[(df[\"treatment\"] == 1) & (df[\"amount\"] &gt; 0)][\"amount\"].values\n\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(1000):\n        treat_sample = np.random.choice(treat_data, size=n, replace=True)\n        ctrl_sample = np.random.choice(control_data, size=n, replace=True)\n        diffs.append(treat_sample.mean() - ctrl_sample.mean())\n    \n    ax = axes[i]\n    ax.hist(diffs, bins=30, color='skyblue', edgecolor='white')\n    ax.axvline(0, color='red', linestyle='--', linewidth=2)\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Difference in Mean Donation (Treatment - Control)\")\n    ax.set_ylabel(\"Frequency\")\n\nplt.suptitle(\"Distribution of Simulated Mean Differences\", fontsize=16, fontweight='bold')\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()"
  },
  {
    "objectID": "homework/hw1_questions.html",
    "href": "homework/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this field experiment, each donor in the sample was randomly assigned to receive one of several versions of a fundraising letter. The control group received the nonprofit’s standard appeal—a typical letter asking for support, with no mention of any special incentives.\nThe treatment group, on the other hand, received letters that included a matching grant offer. These letters stated that a concerned member of the organization would match the recipient’s donation at a fixed rate. Every dollar donated would be matched immediately, increasing the total contribution the organization would receive.\nThe treatment letters varied across three key dimensions:\n\nMatching ratio\nDonors were randomly assigned to receive a match offer of 1:1, 2:1, or 3:1, meaning the organization would receive $2, $3, or $4 for every $1 donated.\nMaximum match amount\nThe total available match funding was stated as either $25,000, $50,000, $100,000, or left unstated.\nSuggested donation amount\nEach letter included a reply card with three suggested gift levels based on the donor’s previous highest contribution: the same amount, 1.25×, or 1.5×. One of these was used as an example in the match statement.\n\nAside from these randomized variations, all letters were identical in format, tone, and content. This design allowed the researchers to isolate the effect of the matching grant mechanism and its specific features on donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homework/hw1_questions.html#introduction",
    "href": "homework/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this field experiment, each donor in the sample was randomly assigned to receive one of several versions of a fundraising letter. The control group received the nonprofit’s standard appeal—a typical letter asking for support, with no mention of any special incentives.\nThe treatment group, on the other hand, received letters that included a matching grant offer. These letters stated that a concerned member of the organization would match the recipient’s donation at a fixed rate. Every dollar donated would be matched immediately, increasing the total contribution the organization would receive.\nThe treatment letters varied across three key dimensions:\n\nMatching ratio\nDonors were randomly assigned to receive a match offer of 1:1, 2:1, or 3:1, meaning the organization would receive $2, $3, or $4 for every $1 donated.\nMaximum match amount\nThe total available match funding was stated as either $25,000, $50,000, $100,000, or left unstated.\nSuggested donation amount\nEach letter included a reply card with three suggested gift levels based on the donor’s previous highest contribution: the same amount, 1.25×, or 1.5×. One of these was used as an example in the match statement.\n\nAside from these randomized variations, all letters were identical in format, tone, and content. This design allowed the researchers to isolate the effect of the matching grant mechanism and its specific features on donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homework/hw1_questions.html#data",
    "href": "homework/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset consists of 50,083 observations and 51 variables, representing prior donors who were part of a large-scale direct mail fundraising experiment. Each row corresponds to an individual who received a solicitation letter, and the variables capture both treatment assignments and individual characteristics.\nThe bar plots show the distribution of key categorical variables in the dataset. The sample is unbalanced across treatment groups by design, with approximately two-thirds assigned to treatment. Only 2.1% of individuals donated, indicating a low response rate. Most of the sample resides in blue states (59.5%), and the majority of donors are male (70.6%) and not donating as a couple (88.7%).\nThe histograms of numeric variables show that both donation-related and historical giving behaviors are highly skewed to the right. Most donation amounts are under $100, and both highest past donation and frequency of past donations exhibit long right tails, suggesting that a small subset of donors account for a disproportionately large share of past giving. The recency variable (mrm2) also shows many donors who haven’t contributed recently, with the most frequent values clustered between 0 and 12 months.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# categorical\ncategorical_vars = ['treatment', 'gave', 'red0', 'female', 'couple']\nlabel_map = {\n    'treatment': {0: 'Control', 1: 'Treatment'},\n    'gave': {0: 'Did Not Give', 1: 'Gave'},\n    'red0': {0: 'Blue State', 1: 'Red State'},\n    'female': {0: 'Male', 1: 'Female'},\n    'couple': {0: 'Single', 1: 'Couple'}\n}\n\nfig, axes = plt.subplots(2, 3, figsize=(16, 8))\naxes = axes.flatten()\n\nfor i, var in enumerate(categorical_vars):\n    ax = axes[i]\n    counts = df[var].value_counts().sort_index()\n    labels = list(label_map[var].values())\n    bars = ax.bar(labels, counts.values, color=sns.color_palette(\"pastel\"))\n\n    for bar, count in zip(bars, counts.values):\n        pct = count / df.shape[0]\n        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{pct:.1%}',\n                ha='center', va='bottom', fontsize=9)\n\n    ax.set_title(f\"{var.capitalize()} Distribution\")\n    ax.set_ylabel(\"Count\")\n\nif len(categorical_vars) &lt; len(axes):\n    fig.delaxes(axes[-1])\n\nplt.tight_layout()\nplt.show()\n\n# numeric\nnumeric_vars = ['amount', 'hpa', 'mrm2', 'freq']\ntitles = {\n    'amount': 'Donation Amount',\n    'hpa': 'Highest Past Donation',\n    'mrm2': 'Months Since Last Donation',\n    'freq': 'Donation Frequency'\n}\n\nxlims = {\n    'amount': (0, 200),\n    'hpa': (0, 250),\n    'mrm2': (0, 60),\n    'freq': (0, 50)\n}\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 6))\naxes = axes.flatten()\n\nfor i, var in enumerate(numeric_vars):\n    ax = axes[i]\n    data = df[df['gave'] == 1][var] if var == 'amount' else df[var]\n    \n    sns.histplot(data, bins=30, kde=True, ax=ax, color='skyblue')\n    ax.set_title(titles[var])\n    ax.set_xlabel(var)\n    ax.set_ylabel(\"Frequency\")\n    ax.set_xlim(xlims[var])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")  \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy.stats import t as t_dist\n\n# Variables\ntest_vars = ['mrm2', 'hpa', 'freq']\nvar_labels = {\n    'mrm2': 'Months Since Last Donation',\n    'hpa': 'Highest Past Donation',\n    'freq': 'Donation Frequency'\n}\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\naxes = axes.flatten()\n\nfor i, var in enumerate(test_vars):\n    means = [\n        df[df['treatment'] == 0][var].mean(),\n        df[df['treatment'] == 1][var].mean()\n    ]\n    labels = ['Control', 'Treatment']\n    colors = ['#6baed6', '#fd8d3c']\n\n    bars = axes[i].bar(labels, means, color=colors)\n    axes[i].set_title(var_labels[var])\n    axes[i].set_ylabel(\"Mean\")\n\n    # Add value labels\n    for bar, mean in zip(bars, means):\n        axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n                     f\"{mean:.2f}\", ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\n# t-test and regression comparison\nresults = []\n\nfor var in test_vars:\n    x1 = df[df[\"treatment\"] == 1][var].dropna()\n    x0 = df[df[\"treatment\"] == 0][var].dropna()\n\n    mean1 = x1.mean()\n    mean0 = x0.mean()\n    diff = mean1 - mean0\n    var1 = x1.var(ddof=1)\n    var0 = x0.var(ddof=1)\n    n1 = len(x1)\n    n0 = len(x0)\n\n    se = np.sqrt(var1 / n1 + var0 / n0)\n    t_stat = diff / se\n\n    df_denom = (var1/n1 + var0/n0)**2 / ((var1**2 / (n1**2 * (n1 - 1))) + (var0**2 / (n0**2 * (n0 - 1))))\n    ttest_p = 2 * (1 - t_dist.cdf(abs(t_stat), df=df_denom))\n\n    X = sm.add_constant(df[['treatment']])\n    model = sm.OLS(df[var], X, missing='drop').fit()\n    reg_t = model.tvalues['treatment']\n    reg_p = model.pvalues['treatment']\n\n    results.append({\n        'Variable': var,\n        'Mean_Treatment': round(mean1, 3),\n        'Mean_Control': round(mean0, 3),\n        'Difference': round(diff, 3),\n        'T-test t': round(t_stat, 3),\n        'T-test p': round(ttest_p, 4),\n        'Reg t': round(reg_t, 3),\n        'Reg p-value': round(reg_p, 4)\n    })\n\npd.DataFrame(results)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean_Treatment\nMean_Control\nDifference\nT-test t\nT-test p\nReg t\nReg p-value\n\n\n\n\n0\nmrm2\n13.012\n12.998000\n0.014\n0.120\n0.9049\n0.119\n0.9049\n\n\n1\nhpa\n59.597\n58.959999\n0.637\n0.970\n0.3318\n0.944\n0.3451\n\n\n2\nfreq\n8.035\n8.047000\n-0.012\n-0.111\n0.9117\n-0.111\n0.9117\n\n\n\n\n\n\n\nThe bar plots visually confirm that the treatment and control groups are nearly identical in their pre-treatment characteristics. There is no meaningful difference in the average months since last donation, highest past donation, or donation frequency.\nStatistical tests further support this conclusion. Both t-tests (using the class formula) and simple regressions yield non-significant results at the 95% confidence level, with very small t-statistics and large p-values across all variables.\nThese findings align with Table 1 in Karlan and List (2007), providing strong evidence that the random assignment was successfully implemented and that treatment and control groups are balanced in observable covariates. This supports the internal validity of any subsequent causal analysis."
  },
  {
    "objectID": "homework/hw1_questions.html#experimental-results",
    "href": "homework/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\n\ndonation_rates = df.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\ncolors = ['#6baed6', '#fd8d3c']\n\n# Plot\nfig, ax = plt.subplots(figsize=(6, 4))\nbars = ax.bar(labels, donation_rates.values, color=colors)\n\nfor bar, rate in zip(bars, donation_rates.values):\n    ax.text(bar.get_x() + bar.get_width() / 2,\n            bar.get_height() + 0.002,\n            f\"{rate:.2%}\", ha='center', va='bottom', fontsize=10)\n\nax.set_ylabel(\"Proportion Donated\")\nax.set_title(\"Donation Rate by Treatment Group\")\nplt.ylim(0, max(donation_rates.values) + 0.01)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe treatment group has a higher donation rate (2.20%) than the control group (1.79%), suggesting a positive effect of the matching offer on donor response.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy.stats import t as t_dist\n\ny_treat = df[df[\"treatment\"] == 1][\"gave\"]\ny_ctrl = df[df[\"treatment\"] == 0][\"gave\"]\n\nmean_treat = y_treat.mean()\nmean_ctrl = y_ctrl.mean()\ndiff = mean_treat - mean_ctrl\nn_treat = len(y_treat)\nn_ctrl = len(y_ctrl)\nvar_treat = y_treat.var(ddof=1)\nvar_ctrl = y_ctrl.var(ddof=1)\n\nse = np.sqrt(var_treat / n_treat + var_ctrl / n_ctrl)\nt_stat = diff / se\ndf_denom = (var_treat/n_treat + var_ctrl/n_ctrl)**2 / (\n    (var_treat**2 / (n_treat**2 * (n_treat - 1))) +\n    (var_ctrl**2 / (n_ctrl**2 * (n_ctrl - 1)))\n)\np_val = 2 * (1 - t_dist.cdf(abs(t_stat), df=df_denom))\n\nX = sm.add_constant(df[\"treatment\"])\nmodel = sm.OLS(df[\"gave\"], X, missing ='drop').fit()\n\n# results\nprint(\"T-test result:\")\nprint(f\"  • Mean difference in donation rate (Treatment - Control): { round(diff, 4)}\")\nprint(f\"  • t-statistic: {round(t_stat, 3)}\")\nprint(f\"  • p-value: {round(p_val, 4)}\")\n\nprint(\"\\nLinear regression result:\")\nprint(f\"  • Coefficient on treatment: {round(model.params['treatment'], 4)}\")\nprint(f\"  • t-statistic: {round(model.tvalues['treatment'], 3)}\")\nprint(f\"  • p-value: {round(model.pvalues['treatment'], 4)}\")\n\n\nT-test result:\n  • Mean difference in donation rate (Treatment - Control): 0.0042\n  • t-statistic: 3.209\n  • p-value: 0.0013\n\nLinear regression result:\n  • Coefficient on treatment: 0.0042\n  • t-statistic: 3.101\n  • p-value: 0.0019\n\n\nBoth the t-test and the linear regression show that the treatment group had a higher donation rate than the control group, and this difference is statistically significant at the 1% level. Specifically, receiving a matching grant offer increases the probability of donating by about 0.42 percentage points—rising from roughly 1.79% in the control group to 2.21% in the treatment group. While this absolute change may appear small, it represents a relative increase of over 20%, which is substantial given the typically low baseline response rate in charitable giving.\nTo further support this finding, I estimate a probit model where the outcome is whether a donation was made and the explanatory variable is treatment assignment. The coefficient on treatment is 0.087, which is also statistically significant at the 1% level. Although the coefficient cannot be interpreted directly as a probability, it indicates an increase in the latent propensity to donate among individuals who received the matching message.\nTaken together, the results provide consistent evidence that even modest psychological framing—such as mentioning that a donation will be matched—can meaningfully increase donor response.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\n\nfrom statsmodels.discrete.discrete_model import Probit\nimport statsmodels.api as sm\n\nX = sm.add_constant(df['treatment'])\nprobit_model = Probit(df['gave'], X).fit()\n\nprint(probit_model.summary())\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Mon, 21 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        13:03:36   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nI conduct three pairwise t-tests comparing donation rates between match ratios (2:1 vs. 1:1, 3:1 vs. 1:1, and 3:1 vs. 2:1). The differences in mean donation rates across these groups are all very small and none are statistically significant at the 5% level. All p-values are well above 0.30. This suggests that the presence of a match itself may be sufficient to motivate behavior, while increasing the match ratio beyond 1:1 offers little incremental benefit.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import t as t_dist\n\ntreatment_df = df[df[\"treatment\"] == 1]\n\nratios = {\n    1: treatment_df[treatment_df[\"ratio\"] == 1][\"gave\"],\n    2: treatment_df[treatment_df[\"ratio\"] == 2][\"gave\"],\n    3: treatment_df[treatment_df[\"ratio\"] == 3][\"gave\"]\n}\n\n# t-test\ndef manual_ttest(group1, group2):\n    mean_diff = group1.mean() - group2.mean()\n    se = np.sqrt(group1.var(ddof=1)/len(group1) + group2.var(ddof=1)/len(group2))\n    t_stat = mean_diff / se\n    df_denom = (group1.var(ddof=1)/len(group1) + group2.var(ddof=1)/len(group2))**2 / (\n        (group1.var(ddof=1)**2 / ((len(group1)**2)*(len(group1)-1))) + \n        (group2.var(ddof=1)**2 / ((len(group2)**2)*(len(group2)-1)))\n    )\n    p_val = 2 * (1 - t_dist.cdf(abs(t_stat), df=df_denom))\n    return round(mean_diff, 4), round(t_stat, 3), round(p_val, 4)\n\nresults = []\nfor high, low in [(2, 1), (3, 1), (3, 2)]:\n    diff, t_stat, p_val = manual_ttest(ratios[high], ratios[low])\n    results.append({\n        \"Comparison\": f\"{high}:1 vs {low}:1\",\n        \"Mean Diff\": diff,\n        \"T-stat\": t_stat,\n        \"P-value\": p_val\n    })\n\npd.DataFrame(results)\n\n\n\n\n\n\n\n\n\nComparison\nMean Diff\nT-stat\nP-value\n\n\n\n\n0\n2:1 vs 1:1\n0.0019\n0.965\n0.3345\n\n\n1\n3:1 vs 1:1\n0.0020\n1.015\n0.3101\n\n\n2\n3:1 vs 2:1\n0.0001\n0.050\n0.9600\n\n\n\n\n\n\n\nTo determine whether higher match ratios influence the likelihood of donating, I regress the binary outcome gave on the categorical variable ratio, using only the treatment group. The 1:1 match ratio serves as the reference category, and the model estimates how donation rates differ under 2:1 and 3:1 matching offers.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\n\ntreat_df = df[df[\"ratio\"].isin([1, 2, 3])].copy()\n\ntreat_df[\"ratio\"] = treat_df[\"ratio\"].astype(\"category\")\n\nimport statsmodels.formula.api as smf\nmodel = smf.ols(\"gave ~ C(ratio, Treatment(reference=1))\", data=treat_df).fit()\n\nparams = model.params\npvals = model.pvalues\n\nprint(\"Linear regression comparing match ratios (baseline: 1:1):\")\nprint(f\"  • Intercept (1:1 match): {params['Intercept']:.4f}\")\nprint(f\"  • 2:1 vs 1:1 match: Coef = {params['C(ratio, Treatment(reference=1))[T.2]']:.4f}, p = {pvals['C(ratio, Treatment(reference=1))[T.2]']:.4f}\")\nprint(f\"  • 3:1 vs 1:1 match: Coef = {params['C(ratio, Treatment(reference=1))[T.3]']:.4f}, p = {pvals['C(ratio, Treatment(reference=1))[T.3]']:.4f}\")\n\n\nLinear regression comparing match ratios (baseline: 1:1):\n  • Intercept (1:1 match): 0.0207\n  • 2:1 vs 1:1 match: Coef = 0.0019, p = 0.3383\n  • 3:1 vs 1:1 match: Coef = 0.0020, p = 0.3133\n\n\nThe estimated coefficients for ratio2 and ratio3 are positive, suggesting slightly higher donation rates compared to the 1:1 baseline. However, both coefficients are not statistically significant (p-values &gt; 0.3), indicating that the observed differences could be due to random variation rather than a true treatment effect.\nTo assess whether increasing the match ratio leads to higher response, I compared donation rates directly from the data and from the regression coefficients.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\n\nrate_1 = df[(df[\"treatment\"] == 1) & (df[\"ratio\"] == 1)][\"gave\"].mean()\nrate_2 = df[(df[\"treatment\"] == 1) & (df[\"ratio\"] == 2)][\"gave\"].mean()\nrate_3 = df[(df[\"treatment\"] == 1) & (df[\"ratio\"] == 3)][\"gave\"].mean()\n\ndiff_2_vs_1_data = rate_2 - rate_1\ndiff_3_vs_2_data = rate_3 - rate_2\n\ncoef_2 = model.params['C(ratio, Treatment(reference=1))[T.2]']\ncoef_3 = model.params['C(ratio, Treatment(reference=1))[T.3]']\ndiff_3_vs_2_coef = coef_3 - coef_2\n\nprint(\"Donation rate differences (direct from data):\")\nprint(f\"  • 2:1 vs 1:1: {round(diff_2_vs_1_data, 4)}\")\nprint(f\"  • 3:1 vs 2:1: {round(diff_3_vs_2_data, 4)}\")\n\nprint(\"\\nEstimated difference from regression coefficients:\")\nprint(f\"  • 2:1 vs 1:1: {round(coef_2, 4)}\")\nprint(f\"  • 3:1 vs 2:1: {round(diff_3_vs_2_coef, 4)}\")\n\n\nDonation rate differences (direct from data):\n  • 2:1 vs 1:1: 0.0019\n  • 3:1 vs 2:1: 0.0001\n\nEstimated difference from regression coefficients:\n  • 2:1 vs 1:1: 0.0019\n  • 3:1 vs 2:1: 0.0001\n\n\nMoving from a 1:1 to a 2:1 match produced a small increase of 0.19%, while the difference between 3:1 and 2:1 was nearly zero (0.01%). These results were mirrored exactly in the regression estimates.\nIn practical terms, offering a match matters, but increasing the match size does not appear to further improve donation response. For fundraisers, this suggests that a basic 1:1 match may be just as effective as higher ratios, but at a lower cost.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nI regress donation amount on the match ratio using the treatment group, with 1:1 as the reference group. The baseline average donation under 1:1 is $0.94. Compared to this:\n\nThe 2:1 group gives $0.09 more (p = 0.46)\nThe 3:1 group gives almost the same (p = 0.99)\n\nThis suggests that higher match ratios do not meaningfully affect how much people donate, even if they influence whether they donate at all.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\n\nimport statsmodels.formula.api as smf\n\namount_df = df[(df[\"treatment\"] == 1) & (df[\"ratio\"].isin([1, 2, 3]))].copy()\n\n\namount_df[\"ratio\"] = amount_df[\"ratio\"].astype(\"category\")\namount_df[\"ratio\"] = amount_df[\"ratio\"].cat.remove_unused_categories()\n\nmodel_amount = smf.ols(\"amount ~ C(ratio, Treatment(reference=1))\", data=amount_df).fit()\n\nmodel_amount.summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.3651\n\n\nDate:\nMon, 21 Apr 2025\nProb (F-statistic):\n0.694\n\n\nTime:\n13:03:37\nLog-Likelihood:\n-1.2063e+05\n\n\nNo. Observations:\n33396\nAIC:\n2.413e+05\n\n\nDf Residuals:\n33393\nBIC:\n2.413e+05\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.9367\n0.085\n11.026\n0.000\n0.770\n1.103\n\n\nC(ratio, Treatment(reference=1))[T.2]\n0.0895\n0.120\n0.745\n0.456\n-0.146\n0.325\n\n\nC(ratio, Treatment(reference=1))[T.3]\n0.0011\n0.120\n0.009\n0.993\n-0.234\n0.237\n\n\n\n\n\n\n\n\nOmnibus:\n64921.717\nDurbin-Watson:\n2.010\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n172634606.522\n\n\nSkew:\n15.430\nProb(JB):\n0.00\n\n\nKurtosis:\n353.872\nCond. No.\n3.73\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n I regress donation amount on the match ratio using only individuals who made a donation. The average donation in the 1:1 group is $45.14. Compared to this:\n\nThe 2:1 group gives $0.19 more (p = 0.96)\nThe 3:1 group gives $3.89 less (p = 0.31)\n\nThese differences are small and statistically insignificant. This suggests that once someone decides to donate, the size of the match does not influence how much they give.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\n\nimport statsmodels.formula.api as smf\n\namount_df = df[(df[\"treatment\"] == 1) & (df[\"amount\"] &gt; 0) & (df[\"ratio\"].isin([1, 2, 3]))].copy()\n\namount_df[\"ratio\"] = amount_df[\"ratio\"].astype(\"category\")\namount_df[\"ratio\"] = amount_df[\"ratio\"].cat.remove_unused_categories()\n\nmodel_amount = smf.ols(\"amount ~ C(ratio, Treatment(reference=1))\", data=amount_df).fit()\n\nmodel_amount.summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.002\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.001\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.7504\n\n\nDate:\nMon, 21 Apr 2025\nProb (F-statistic):\n0.473\n\n\nTime:\n13:03:37\nLog-Likelihood:\n-3794.3\n\n\nNo. Observations:\n736\nAIC:\n7595.\n\n\nDf Residuals:\n733\nBIC:\n7608.\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n45.1429\n2.765\n16.324\n0.000\n39.714\n50.572\n\n\nC(ratio, Treatment(reference=1))[T.2]\n0.1944\n3.829\n0.051\n0.960\n-7.322\n7.711\n\n\nC(ratio, Treatment(reference=1))[T.3]\n-3.8911\n3.825\n-1.017\n0.309\n-11.400\n3.618\n\n\n\n\n\n\n\n\nOmnibus:\n458.865\nDurbin-Watson:\n1.918\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n5192.758\n\n\nSkew:\n2.659\nProb(JB):\n0.00\n\n\nKurtosis:\n14.876\nCond. No.\n3.83\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n The histograms display the distribution of donation amounts among individuals who donated, separated by treatment and control groups. Both distributions are heavily right-skewed, with most donations concentrated under $100.\nThe treatment group’s average donation is $43.87, while the control group’s average is slightly higher at $45.54. Despite the visual and numerical difference, the gap is small and not statistically significant, reinforcing earlier regression results that match offers influence whether people give, but not how much they give once they’ve decided to donate.\n\n\nCode\nimport pandas as pd\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndonors = df[df[\"amount\"] &gt; 0]\n\ndonors_treat = donors[donors[\"treatment\"] == 1]\ndonors_ctrl = donors[donors[\"treatment\"] == 0]\n\nmean_treat = donors_treat[\"amount\"].mean()\nmean_ctrl = donors_ctrl[\"amount\"].mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# treatment group\nsns.histplot(donors_treat[\"amount\"], bins=30, ax=axes[0], color='skyblue')\naxes[0].axvline(mean_treat, color='red', linestyle='--')  # Add vertical line for mean\naxes[0].set_title(\"Treatment\")\naxes[0].set_xlabel(\"Donation Amount\")\naxes[0].set_ylabel(\"Number of Donors\")\naxes[0].text(mean_treat + 2, axes[0].get_ylim()[1]*0.9, f\"Mean = ${mean_treat:.2f}\", color='red')\n\n# control group\nsns.histplot(donors_ctrl[\"amount\"], bins=30, ax=axes[1], color='lightgreen')\naxes[1].axvline(mean_ctrl, color='red', linestyle='--')\naxes[1].set_title(\"Control\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].text(mean_ctrl + 2, axes[1].get_ylim()[1]*0.9, f\"Mean = ${mean_ctrl:.2f}\", color='red')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "homework/hw1_questions.html#simulation-experiment",
    "href": "homework/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nThe plot shows the cumulative average difference in donation amounts between the treatment and control groups, based on 10,000 simulated donor pairs. Initially, the cumulative average fluctuates substantially, reflecting noise in small samples. As the number of simulated pairs increases, the cumulative average steadily converges toward the true mean difference (indicated by the red dashed line).\nThis pattern illustrates the Law of Large Numbers: with enough data, the average of simulated differences approximates the population-level treatment effect. In this case, the cumulative average stabilizes around the true mean difference, providing visual confirmation that our estimate becomes more reliable as sample size increases.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\nnp.random.seed(123)\n\ncontrol_data = df[(df[\"treatment\"] == 0) & (df[\"amount\"] &gt; 0)][\"amount\"]\ntreat_data = df[(df[\"treatment\"] == 1) & (df[\"amount\"] &gt; 0)][\"amount\"]\n\n# simulation\ncontrol_draws = np.random.choice(control_data, size=100000, replace=True)\ntreat_draws = np.random.choice(treat_data, size=10000, replace=True)\n\ndiffs = treat_draws - control_draws[:10000]\ncum_avg_diff = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\ntrue_diff = treat_data.mean() - control_data.mean()\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cum_avg_diff, label=\"Cumulative Avg. Difference\", color='steelblue', linewidth=2)\nplt.axhline(y=true_diff, color='crimson', linestyle='--', linewidth=2, label=\"True Mean Difference\")\n\nplt.xlabel(\"Number of Simulated Pairs\", fontsize=12)\nplt.ylabel(\"Cumulative Average (Treatment - Control)\", fontsize=12)\nplt.title(\"Cumulative Average of Donation Differences\\nSimulated from Treatment and Control Groups\", fontsize=14, fontweight='bold')\nplt.legend()\nplt.grid(alpha=0.3)\nplt.xlim(0, 10000)\nplt.ylim(-20, 20)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nThese histograms show the distribution of simulated mean donation differences (treatment minus control) across 1000 replications, at four different sample sizes.\nAs the sample size increases, the distributions become narrower and more centered. This reflects a reduction in uncertainty—with small samples, estimates of the mean difference vary widely due to random noise. As the number of observations grows, the law of large numbers ensures that sample estimates converge toward the true underlying difference, and the variability across simulations shrinks.\nAt all sample sizes, the distributions tend to center slightly below zero, which is consistent with the observed data where treatment donors gave slightly less than control donors, on average. While the difference is small and not statistically significant, the simulation reinforces that larger sample sizes produce more stable and precise estimates, even when the underlying effect is near zero.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_stata(\"../data/karlan_list_2007.dta\")\nnp.random.seed(123)\n\ncontrol_data = df[(df[\"treatment\"] == 0) & (df[\"amount\"] &gt; 0)][\"amount\"].values\ntreat_data = df[(df[\"treatment\"] == 1) & (df[\"amount\"] &gt; 0)][\"amount\"].values\n\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(1000):\n        treat_sample = np.random.choice(treat_data, size=n, replace=True)\n        ctrl_sample = np.random.choice(control_data, size=n, replace=True)\n        diffs.append(treat_sample.mean() - ctrl_sample.mean())\n    \n    ax = axes[i]\n    ax.hist(diffs, bins=30, color='skyblue', edgecolor='white')\n    ax.axvline(0, color='red', linestyle='--', linewidth=2)\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Difference in Mean Donation (Treatment - Control)\")\n    ax.set_ylabel(\"Frequency\")\n\nplt.suptitle(\"Distribution of Simulated Mean Differences\", fontsize=16, fontweight='bold')\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()"
  },
  {
    "objectID": "homework/hw2_questions.html",
    "href": "homework/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\nCode\nimport pandas as pd\ndf = pd.read_csv(\"../data/blueprinty.csv\")\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n\ndf[df['iscustomer'] == 1]['patents'].hist(ax=ax[0], bins=10, color='skyblue')\nax[0].set_title('Customers')\nax[0].set_xlabel('Number of Patents')\n\ndf[df['iscustomer'] == 0]['patents'].hist(ax=ax[1], bins=10, color='salmon')\nax[1].set_title('Non-Customers')\nax[1].set_xlabel('Number of Patents')\n\nfig.suptitle('Histogram of Patents by Customer Status')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf.groupby('iscustomer')['patents'].mean()\n\n\niscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n\n\nCustomers tend to have more patents on average (4.13 vs. 3.47), and their distribution is more spread out, with more firms holding a higher number of patents. Non-customers are more concentrated at lower patent counts.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\nCode\nimport seaborn as sns\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 4))\n\nsns.countplot(data=df, x='region', hue='iscustomer', ax=axs[0])\naxs[0].set_title('Region by Customer Status')\naxs[0].set_xlabel('Region')\naxs[0].set_ylabel('Count')\naxs[0].legend(title='Customer')\n\nsns.kdeplot(data=df, x='age', hue='iscustomer', ax=axs[1], fill=True)\naxs[1].set_title('Age Distribution by Customer Status')\naxs[1].set_xlabel('Age')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf.groupby('iscustomer')['age'].mean()\n\n\niscustomer\n0    26.101570\n1    26.900208\nName: age, dtype: float64\n\n\nCustomers tend to be slightly older (average age 26.9 vs. 26.1). The regional distribution shows a clear difference: a much higher number of customers come from the Northeast, while other regions like the Midwest and Southwest are dominated by non-customers.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nWe assume the number of patents \\(Y \\sim \\text{Poisson}(\\lambda)\\), with density:\n\\[\nf(Y \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\n\\]\nFor a sample \\(Y_1, Y_2, \\dots, Y_n\\), the log-likelihood is:\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^n \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nLog-Likelihood Function in Python\n\n\nCode\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_log_likelihood(lmbda, y):\n    y = np.asarray(y)\n    return np.sum(-lmbda + y * np.log(lmbda) - gammaln(y + 1))\n\n\nPlotting the Log-Likelihood Curve\n\n\nCode\nimport matplotlib.pyplot as plt\n\ny = df['patents'].values\nlambdas = np.linspace(0.1, 10, 100)\nlogliks = [poisson_log_likelihood(lmbda, y) for lmbda in lambdas]\n\nplt.plot(lambdas, logliks)\nplt.xlabel(\"λ (lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Poisson Log-Likelihood for Different λ\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nThe analytical MLE for \\(\\lambda\\) is simply the sample mean of \\(Y\\), since:\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\n\\] Sample Mean\n\n\nCode\nybar = np.mean(y)\nybar\n\n\n3.6846666666666668\n\n\nNumerical Maximization Using scipy.optimize\n\n\nCode\nfrom scipy.optimize import minimize\n\ndef neg_log_likelihood(lmbda):\n    return -poisson_log_likelihood(lmbda[0], y)\n\nresult = minimize(neg_log_likelihood, x0=[1.0], bounds=[(0.001, None)])\nresult.x[0]\n\n\n3.6846662953477973\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nWe now extend our Poisson model to allow the rate of patent awards to depend on firm characteristics via:\n\\[\nY_i \\sim \\text{Poisson}(\\lambda_i), \\quad \\text{where } \\lambda_i = \\exp(X_i^\\top \\beta)\n\\]\nCovariates include: age, age squared, region (as dummies), and whether the firm is a Blueprinty customer.\n\n\n\n\nCode\nimport pandas as pd\nimport statsmodels.api as sm\n\ndf['age_squared'] = df['age'] ** 2\nX_df = pd.get_dummies(df[['age', 'age_squared', 'region', 'iscustomer']], drop_first=True)\nX_df = sm.add_constant(X_df)\n\nX_df = X_df.astype(float)\nX = X_df\ny = df['patents'].values\n\n\n\n\n\n\n\nCode\nimport statsmodels.api as sm\n\nmodel = sm.GLM(y, X, family=sm.families.Poisson())\nglm_result = model.fit()\n\nglm_result.summary()\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ny\nNo. Observations:\n1500\n\n\nModel:\nGLM\nDf Residuals:\n1492\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3258.1\n\n\nDate:\nFri, 02 May 2025\nDeviance:\n2143.3\n\n\nTime:\n21:51:48\nPearson chi2:\n2.07e+03\n\n\nNo. Iterations:\n5\nPseudo R-squ. (CS):\n0.1360\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-0.5089\n0.183\n-2.778\n0.005\n-0.868\n-0.150\n\n\nage\n0.1486\n0.014\n10.716\n0.000\n0.121\n0.176\n\n\nage_squared\n-0.0030\n0.000\n-11.513\n0.000\n-0.003\n-0.002\n\n\niscustomer\n0.2076\n0.031\n6.719\n0.000\n0.147\n0.268\n\n\nregion_Northeast\n0.0292\n0.044\n0.669\n0.504\n-0.056\n0.115\n\n\nregion_Northwest\n-0.0176\n0.054\n-0.327\n0.744\n-0.123\n0.088\n\n\nregion_South\n0.0566\n0.053\n1.074\n0.283\n-0.047\n0.160\n\n\nregion_Southwest\n0.0506\n0.047\n1.072\n0.284\n-0.042\n0.143\n\n\n\n\n\n\n\n\n\n\nCode\nsummary_df = pd.DataFrame({\n    \"Coefficient\": glm_result.params,\n    \"Std. Error\": glm_result.bse,\n    \"z-value\": glm_result.tvalues,\n    \"p-value\": glm_result.pvalues\n})\n\nsummary_df\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\nz-value\np-value\n\n\n\n\nconst\n-0.508920\n0.183179\n-2.778269\n5.464935e-03\n\n\nage\n0.148619\n0.013869\n10.716250\n8.539597e-27\n\n\nage_squared\n-0.002970\n0.000258\n-11.513237\n1.131496e-30\n\n\niscustomer\n0.207591\n0.030895\n6.719179\n1.827509e-11\n\n\nregion_Northeast\n0.029170\n0.043625\n0.668647\n5.037205e-01\n\n\nregion_Northwest\n-0.017575\n0.053781\n-0.326782\n7.438327e-01\n\n\nregion_South\n0.056561\n0.052662\n1.074036\n2.828066e-01\n\n\nregion_Southwest\n0.050576\n0.047198\n1.071568\n2.839141e-01\n\n\n\n\n\n\n\n\n\n\nFirms that are Blueprinty customers are expected to produce about 23%(i.e. exp(0.2076)-1) more patents than non-customers, holding other factors constant. This effect is statistically significant.\nPatent output increases with firm age, but at a decreasing rate—suggesting older firms patent more, but the effect tapers off.\nRegional differences are not statistically significant, indicating little variation in patenting across regions once other firm characteristics are controlled for.\n\n\n\nWe create two fake datasets: - X_0 with iscustomer = 0 for all firms (as if no firm were a customer) - X_1 with iscustomer = 1 for all firms (as if all firms were customers)\nWe use the fitted model to compute predicted number of patents for each case, then take the difference.\n\n\nCode\nX_0 = X.copy()\nX_1 = X.copy()\n\nX_0.loc[:, X.columns.str.contains(\"iscustomer\")] = 0\nX_1.loc[:, X.columns.str.contains(\"iscustomer\")] = 1\n\n# Predict expected patent counts\ny_pred_0 = glm_result.predict(X_0)\ny_pred_1 = glm_result.predict(X_1)\n\n# Difference in predicted patents\ndiff = y_pred_1 - y_pred_0\ndiff.mean()\n\n\n0.7927680710452626\n\n\n\n\n\nOn average, firms are predicted to receive 0.79(i.e. 3.47 * 0.23) more patents over five years if they are Blueprinty customers, compared to if they are not—holding all other firm characteristics constant. This suggests a meaningful positive effect of the software on patenting success."
  },
  {
    "objectID": "homework/hw2_questions.html#blueprinty-case-study",
    "href": "homework/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\nCode\nimport pandas as pd\ndf = pd.read_csv(\"../data/blueprinty.csv\")\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n\ndf[df['iscustomer'] == 1]['patents'].hist(ax=ax[0], bins=10, color='skyblue')\nax[0].set_title('Customers')\nax[0].set_xlabel('Number of Patents')\n\ndf[df['iscustomer'] == 0]['patents'].hist(ax=ax[1], bins=10, color='salmon')\nax[1].set_title('Non-Customers')\nax[1].set_xlabel('Number of Patents')\n\nfig.suptitle('Histogram of Patents by Customer Status')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf.groupby('iscustomer')['patents'].mean()\n\n\niscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n\n\nCustomers tend to have more patents on average (4.13 vs. 3.47), and their distribution is more spread out, with more firms holding a higher number of patents. Non-customers are more concentrated at lower patent counts.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\nCode\nimport seaborn as sns\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 4))\n\nsns.countplot(data=df, x='region', hue='iscustomer', ax=axs[0])\naxs[0].set_title('Region by Customer Status')\naxs[0].set_xlabel('Region')\naxs[0].set_ylabel('Count')\naxs[0].legend(title='Customer')\n\nsns.kdeplot(data=df, x='age', hue='iscustomer', ax=axs[1], fill=True)\naxs[1].set_title('Age Distribution by Customer Status')\naxs[1].set_xlabel('Age')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf.groupby('iscustomer')['age'].mean()\n\n\niscustomer\n0    26.101570\n1    26.900208\nName: age, dtype: float64\n\n\nCustomers tend to be slightly older (average age 26.9 vs. 26.1). The regional distribution shows a clear difference: a much higher number of customers come from the Northeast, while other regions like the Midwest and Southwest are dominated by non-customers.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nWe assume the number of patents \\(Y \\sim \\text{Poisson}(\\lambda)\\), with density:\n\\[\nf(Y \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\n\\]\nFor a sample \\(Y_1, Y_2, \\dots, Y_n\\), the log-likelihood is:\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^n \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nLog-Likelihood Function in Python\n\n\nCode\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_log_likelihood(lmbda, y):\n    y = np.asarray(y)\n    return np.sum(-lmbda + y * np.log(lmbda) - gammaln(y + 1))\n\n\nPlotting the Log-Likelihood Curve\n\n\nCode\nimport matplotlib.pyplot as plt\n\ny = df['patents'].values\nlambdas = np.linspace(0.1, 10, 100)\nlogliks = [poisson_log_likelihood(lmbda, y) for lmbda in lambdas]\n\nplt.plot(lambdas, logliks)\nplt.xlabel(\"λ (lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Poisson Log-Likelihood for Different λ\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nThe analytical MLE for \\(\\lambda\\) is simply the sample mean of \\(Y\\), since:\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\n\\] Sample Mean\n\n\nCode\nybar = np.mean(y)\nybar\n\n\n3.6846666666666668\n\n\nNumerical Maximization Using scipy.optimize\n\n\nCode\nfrom scipy.optimize import minimize\n\ndef neg_log_likelihood(lmbda):\n    return -poisson_log_likelihood(lmbda[0], y)\n\nresult = minimize(neg_log_likelihood, x0=[1.0], bounds=[(0.001, None)])\nresult.x[0]\n\n\n3.6846662953477973\n\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nWe now extend our Poisson model to allow the rate of patent awards to depend on firm characteristics via:\n\\[\nY_i \\sim \\text{Poisson}(\\lambda_i), \\quad \\text{where } \\lambda_i = \\exp(X_i^\\top \\beta)\n\\]\nCovariates include: age, age squared, region (as dummies), and whether the firm is a Blueprinty customer.\n\n\n\n\nCode\nimport pandas as pd\nimport statsmodels.api as sm\n\ndf['age_squared'] = df['age'] ** 2\nX_df = pd.get_dummies(df[['age', 'age_squared', 'region', 'iscustomer']], drop_first=True)\nX_df = sm.add_constant(X_df)\n\nX_df = X_df.astype(float)\nX = X_df\ny = df['patents'].values\n\n\n\n\n\n\n\nCode\nimport statsmodels.api as sm\n\nmodel = sm.GLM(y, X, family=sm.families.Poisson())\nglm_result = model.fit()\n\nglm_result.summary()\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ny\nNo. Observations:\n1500\n\n\nModel:\nGLM\nDf Residuals:\n1492\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3258.1\n\n\nDate:\nFri, 02 May 2025\nDeviance:\n2143.3\n\n\nTime:\n21:51:48\nPearson chi2:\n2.07e+03\n\n\nNo. Iterations:\n5\nPseudo R-squ. (CS):\n0.1360\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-0.5089\n0.183\n-2.778\n0.005\n-0.868\n-0.150\n\n\nage\n0.1486\n0.014\n10.716\n0.000\n0.121\n0.176\n\n\nage_squared\n-0.0030\n0.000\n-11.513\n0.000\n-0.003\n-0.002\n\n\niscustomer\n0.2076\n0.031\n6.719\n0.000\n0.147\n0.268\n\n\nregion_Northeast\n0.0292\n0.044\n0.669\n0.504\n-0.056\n0.115\n\n\nregion_Northwest\n-0.0176\n0.054\n-0.327\n0.744\n-0.123\n0.088\n\n\nregion_South\n0.0566\n0.053\n1.074\n0.283\n-0.047\n0.160\n\n\nregion_Southwest\n0.0506\n0.047\n1.072\n0.284\n-0.042\n0.143\n\n\n\n\n\n\n\n\n\n\nCode\nsummary_df = pd.DataFrame({\n    \"Coefficient\": glm_result.params,\n    \"Std. Error\": glm_result.bse,\n    \"z-value\": glm_result.tvalues,\n    \"p-value\": glm_result.pvalues\n})\n\nsummary_df\n\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\nz-value\np-value\n\n\n\n\nconst\n-0.508920\n0.183179\n-2.778269\n5.464935e-03\n\n\nage\n0.148619\n0.013869\n10.716250\n8.539597e-27\n\n\nage_squared\n-0.002970\n0.000258\n-11.513237\n1.131496e-30\n\n\niscustomer\n0.207591\n0.030895\n6.719179\n1.827509e-11\n\n\nregion_Northeast\n0.029170\n0.043625\n0.668647\n5.037205e-01\n\n\nregion_Northwest\n-0.017575\n0.053781\n-0.326782\n7.438327e-01\n\n\nregion_South\n0.056561\n0.052662\n1.074036\n2.828066e-01\n\n\nregion_Southwest\n0.050576\n0.047198\n1.071568\n2.839141e-01\n\n\n\n\n\n\n\n\n\n\nFirms that are Blueprinty customers are expected to produce about 23%(i.e. exp(0.2076)-1) more patents than non-customers, holding other factors constant. This effect is statistically significant.\nPatent output increases with firm age, but at a decreasing rate—suggesting older firms patent more, but the effect tapers off.\nRegional differences are not statistically significant, indicating little variation in patenting across regions once other firm characteristics are controlled for.\n\n\n\nWe create two fake datasets: - X_0 with iscustomer = 0 for all firms (as if no firm were a customer) - X_1 with iscustomer = 1 for all firms (as if all firms were customers)\nWe use the fitted model to compute predicted number of patents for each case, then take the difference.\n\n\nCode\nX_0 = X.copy()\nX_1 = X.copy()\n\nX_0.loc[:, X.columns.str.contains(\"iscustomer\")] = 0\nX_1.loc[:, X.columns.str.contains(\"iscustomer\")] = 1\n\n# Predict expected patent counts\ny_pred_0 = glm_result.predict(X_0)\ny_pred_1 = glm_result.predict(X_1)\n\n# Difference in predicted patents\ndiff = y_pred_1 - y_pred_0\ndiff.mean()\n\n\n0.7927680710452626\n\n\n\n\n\nOn average, firms are predicted to receive 0.79(i.e. 3.47 * 0.23) more patents over five years if they are Blueprinty customers, compared to if they are not—holding all other firm characteristics constant. This suggests a meaningful positive effect of the software on patenting success."
  },
  {
    "objectID": "homework/hw2_questions.html#airbnb-case-study",
    "href": "homework/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\nLoad and Clean Data\n\n\nCode\nimport pandas as pd\n\ndf = pd.read_csv(\"../data/airbnb.csv\")\n\n# Drop rows with missing values in relevant columns\ndf = df[['days', 'room_type', 'bathrooms', 'bedrooms', 'price', 'number_of_reviews',\n         'review_scores_cleanliness', 'review_scores_location', 'review_scores_value',\n         'instant_bookable']].dropna()\n\n# Convert instant_bookable to binary\ndf['instant_bookable'] = df['instant_bookable'].map({'t': 1, 'f': 0})\n\n\n\n\nExploratory Data Analysis\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Correlation heatmap for numeric features\nnumeric_cols = df.select_dtypes(include='number').columns\ncorr = df[numeric_cols].corr()\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr, annot=True, cmap='coolwarm')\nplt.title(\"Correlation Heatmap of Numeric Variables\")\nplt.show()\n\n# Dashboard 1: Scatter plots of numeric predictors vs number_of_reviews\nfig, axs = plt.subplots(1, 3, figsize=(18, 5))\nsns.scatterplot(x=df['days'], y=df['number_of_reviews'], ax=axs[0])\naxs[0].set_title(\"Reviews vs Days\")\n\nsns.scatterplot(x=df['price'], y=df['number_of_reviews'], ax=axs[1])\naxs[1].set_title(\"Reviews vs Price\")\n\nsns.scatterplot(x=df['review_scores_location'], y=df['number_of_reviews'], ax=axs[2])\naxs[2].set_title(\"Reviews vs Location Score\")\n\nplt.tight_layout()\nplt.show()\n\n# Dashboard 2: Boxplot of reviews by room type\nplt.figure(figsize=(6, 5))\nsns.boxplot(data=df, x='room_type', y='number_of_reviews')\nplt.title(\"Number of Reviews by Room Type\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReview score variables are correlated; don’t include all of them together.\nNumber of reviews is highly skewed — Poisson is reasonable, but check overdispersion.\nHigher prices tend to get fewer reviews; log-transforming price is helpful.\nReviews increase with location score, especially at high values.\nShared rooms get fewer reviews; room type matters and may interact with other variables.\n\n\n\nFit Poisson Regression Model\n\n\nCode\nimport statsmodels.api as sm\n\n# Log and squared transforms\ndf['log_price'] = np.log1p(df['price'])\ndf['log_days'] = np.log1p(df['days'])\n\n# Interaction terms\ndf['price_x_days'] = df['price'] * df['days']\ndf['bookable_x_room'] = df['instant_bookable'] * (df['room_type'] == 'Entire home/apt').astype(int)\n\n\n# Define predictors\nX = df[['log_days','log_price',\n        'review_scores_value', 'instant_bookable',\n        'price_x_days', 'bookable_x_room']]\n\n# Add room type dummies\nroom_dummies = pd.get_dummies(df[['room_type','bedrooms', 'bathrooms']], drop_first=True)\nX = pd.concat([X, room_dummies], axis=1)\n\n# Add intercept\nX = sm.add_constant(X)\nX = X.astype(float)\ny = df['number_of_reviews']\n\nmodel = sm.GLM(y, X, family=sm.families.Poisson())\nglm_result = model.fit()\nglm_result.summary()\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nnumber_of_reviews\nNo. Observations:\n30160\n\n\nModel:\nGLM\nDf Residuals:\n30149\n\n\nModel Family:\nPoisson\nDf Model:\n10\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-4.8964e+05\n\n\nDate:\nFri, 02 May 2025\nDeviance:\n8.5782e+05\n\n\nTime:\n21:51:49\nPearson chi2:\n1.22e+06\n\n\nNo. Iterations:\n7\nPseudo R-squ. (CS):\n0.9680\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-1.0944\n0.027\n-40.254\n0.000\n-1.148\n-1.041\n\n\nlog_days\n0.5646\n0.002\n249.950\n0.000\n0.560\n0.569\n\n\nlog_price\n0.1275\n0.003\n39.293\n0.000\n0.121\n0.134\n\n\nreview_scores_value\n-0.0465\n0.001\n-33.716\n0.000\n-0.049\n-0.044\n\n\ninstant_bookable\n0.4976\n0.004\n124.468\n0.000\n0.490\n0.505\n\n\nprice_x_days\n-2.755e-07\n6.81e-09\n-40.463\n0.000\n-2.89e-07\n-2.62e-07\n\n\nbookable_x_room\n0.0230\n0.006\n3.971\n0.000\n0.012\n0.034\n\n\nbedrooms\n0.0774\n0.002\n37.365\n0.000\n0.073\n0.081\n\n\nbathrooms\n-0.1074\n0.004\n-28.239\n0.000\n-0.115\n-0.100\n\n\nroom_type_Private room\n0.0862\n0.004\n23.458\n0.000\n0.079\n0.093\n\n\nroom_type_Shared room\n0.0090\n0.009\n0.978\n0.328\n-0.009\n0.027\n\n\n\n\n\n\n\nShow Coefficients and Exponentiated Effects\n\n\nCode\ncoef_df = pd.DataFrame({\n    'Coefficient': glm_result.params,\n    'Exp(Coefficient)': np.exp(glm_result.params),\n    'p-value': glm_result.pvalues\n})\n\ncoef_df.sort_values('p-value')  # sort by significance\n\n\n\n\n\n\n\n\n\nCoefficient\nExp(Coefficient)\np-value\n\n\n\n\nconst\n-1.094405e+00\n0.334739\n0.000000e+00\n\n\nlog_days\n5.645793e-01\n1.758708\n0.000000e+00\n\n\nlog_price\n1.274563e-01\n1.135935\n0.000000e+00\n\n\ninstant_bookable\n4.975882e-01\n1.644750\n0.000000e+00\n\n\nprice_x_days\n-2.754803e-07\n1.000000\n0.000000e+00\n\n\nbedrooms\n7.738920e-02\n1.080463\n1.470202e-305\n\n\nreview_scores_value\n-4.651199e-02\n0.954553\n3.400566e-249\n\n\nbathrooms\n-1.074441e-01\n0.898127\n1.967010e-175\n\n\nroom_type_Private room\n8.620330e-02\n1.090028\n1.092157e-121\n\n\nbookable_x_room\n2.297251e-02\n1.023238\n7.168259e-05\n\n\nroom_type_Shared room\n9.039075e-03\n1.009080\n3.280893e-01\n\n\n\n\n\n\n\n\n\nInterpretation\nThe Poisson regression results show that several listing features significantly affect the expected number of reviews:\n\nLog Days has the strongest effect — older listings get substantially more reviews.\nLog Price is positively associated with review count, suggesting that higher-priced listings may attract more engagement.\nInstant Bookable listings receive about 64% more reviews, highlighting convenience as a key factor.\nBedrooms have a moderate positive effect, while bathrooms show a small but negative association.\nReview Score (Value) is negatively associated with reviews, which may reflect multicollinearity with other score metrics.\nRoom Type matters: private rooms receive slightly more reviews, but shared rooms are not significantly different from the baseline (entire home/apt).\nThe interaction terms (price × days, bookable × room) have statistically significant but small effects.\n\nOverall, the model fits well, and the most impactful predictors are listing age, instant bookability, and price."
  }
]